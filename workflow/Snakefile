#--- snakebids boilerplate

import snakebids
from snakebids import bids, filter_list

configfile: 'config/snakebids.yml'

#writes inputs_config.yml and updates config dict
snakebids.generate_inputs_config(config)

#this adds constraints to the bids naming
wildcard_constraints:  **snakebids.get_wildcard_constraints(config)

 
#--- rest of workflow below

#additional constraints for wildcards not defined from inputs
wildcard_constraints:
    desc='[a-zA-Z0-9]+',
    fwhm='[0-9]+',
    confounds='[0-9]+'


# WARNING -- paths for input files (e.g. config/ and resources/) will be relative to output working directory if run via snakebids-app, and thus will not be found.. 
#   current solution is to not use any extra config files 
#   and for resources/ folder, try to generate it on the fly??
#    -- should think about workarounds

#things to explain:
# - using the bids() function to get bids names
# - using input_path to get pybids inputs
# - using **input_wildcards with the bids() function to include wildcards grabbed from pybids  -- introduce more than subject/session
# - using expand() with **subj_wildcards to automatically deal with optional session-level
# - using expand() with input_lists to specify values in target rules
# - using expand() with input_zip_lists when not all combinations of wildcards exist
# - using filter_list() when need to expand over subset of wildcards


rule all:
    input: 
        # using the zip lists to expand over all scans, note use of the zip option in expand:
        denoised = expand(
                        expand(
                            bids(root='results',datatype='func',desc='{{desc}}',fwhm='{{fwhm}}',confounds='{{confounds_idx}}',suffix='bold.nii.gz',**config['input_wildcards']['preproc_bold']),
                             zip, **config['input_zip_lists']['preproc_bold']),
                        fwhm=config['fwhm'],confounds_idx=range(1,len(config['confounds'])+1),desc=['denoised','AROMAdenoised'])

  
rule smooth:
    input:
        nii = config['input_path']['preproc_bold'],
        json = re.sub('.nii.gz','.json',config['input_path']['preproc_bold'])
    params:
        fwhm = lambda wildcards: float(wildcards.fwhm)
    output:
        nii = bids(root='results',datatype='func',desc='smoothed',fwhm='{fwhm}',suffix='bold.nii.gz',**config['input_wildcards']['preproc_bold']),
        json = bids(root='results',datatype='func',desc='smoothed',fwhm='{fwhm}',suffix='bold.json',**config['input_wildcards']['preproc_bold'])
    script: 'scripts/smooth.py'




rule denoise:
    input: 
        nii = bids(root='results',datatype='func',desc='smoothed',fwhm='{fwhm}',suffix='bold.nii.gz',**config['input_wildcards']['preproc_bold']),
        json = bids(root='results',datatype='func',desc='smoothed',fwhm='{fwhm}',suffix='bold.json',**config['input_wildcards']['preproc_bold']),
        confounds_tsv = config['input_path']['confounds'],
        mask_nii = config['input_path']['preproc_mask']
    params:
        confounds_to_use = lambda wildcards: config['confounds'][int(wildcards.confounds_idx)-1]['regressors'],
        confounds_name = lambda wildcards: config['confounds'][int(wildcards.confounds_idx)-1]['name'],
        standardize = True,
        detrend = True,
        low_pass = False,
        high_pass = False,
    output: 
        nii = bids(root='results',datatype='func',desc='denoised',fwhm='{fwhm}',confounds='{confounds_idx}',suffix='bold.nii.gz',**config['input_wildcards']['preproc_bold']),
        json= bids(root='results',datatype='func',desc='denoised',fwhm='{fwhm}',confounds='{confounds_idx}',suffix='bold.json',**config['input_wildcards']['preproc_bold'])
    script: 'scripts/denoise.py'

                

rule aroma_nonaggr:
    input: 
        nii = bids(root='results',datatype='func',desc='smoothed',fwhm='{fwhm}',suffix='bold.nii.gz',**config['input_wildcards']['preproc_bold']),
        mixing = config['input_path']['mixing'],
        noiseICs = config['input_path']['noiseICs'],
        mask_nii = config['input_path']['preproc_mask']
    params:
        container = config['singularity']['fsl']
    output: 
        nii = bids(root='results',datatype='func',desc='AROMAnonaggr',fwhm='{fwhm}',suffix='bold.nii.gz',**config['input_wildcards']['preproc_bold']),
    container: config['singularity']['fsl']
    shell:
        'fsl_regfilt -i {input.nii} -f `cat {input.noiseICs}` -d {input.mixing} -o {output.nii} -m {input.mask_nii}' 

#this regresses out confounds after aroma 
rule aroma_aggr:
    input: 
        nii = bids(root='results',datatype='func',desc='AROMAnonaggr',fwhm='{fwhm}',suffix='bold.nii.gz',**config['input_wildcards']['preproc_bold']),
        json = bids(root='results',datatype='func',desc='smoothed',fwhm='{fwhm}',suffix='bold.json',**config['input_wildcards']['preproc_bold']),
        confounds_tsv = config['input_path']['confounds'],
        mask_nii = config['input_path']['preproc_mask']
    params:
        confounds_to_use = lambda wildcards: config['confounds'][int(wildcards.confounds_idx)-1]['regressors'],
        confounds_name = lambda wildcards: config['confounds'][int(wildcards.confounds_idx)-1]['name'],
        standardize = True,
        detrend = True,
        low_pass = False,
        high_pass = False,
    output: 
        nii = bids(root='results',datatype='func',desc='AROMAdenoised',fwhm='{fwhm}',confounds='{confounds_idx}',suffix='bold.nii.gz',**config['input_wildcards']['preproc_bold']),
        json= bids(root='results',datatype='func',desc='AROMAdenoised',fwhm='{fwhm}',confounds='{confounds_idx}',suffix='bold.json',**config['input_wildcards']['preproc_bold'])
    script: 'scripts/denoise.py'

    


